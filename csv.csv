"Running my first spider by command"
"Scrapy crawl quotes"
"Received:"
"2019-12-29 14:28:56 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: tutorial)"
"2019-12-29 14:28:56 [scrapy.utils.log] INFO: Versions: lxml 4.4.2.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.3 (v3.7.3:ef4ec6ed12, Mar 25 2019, 16:52:21) - [Clang 6.0 (clang-600.0.57)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Darwin-18.7.0-x86_64-i386-64bit"
"2019-12-29 14:28:56 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'tutorial', 'NEWSPIDER_MODULE': 'tutorial.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['tutorial.spiders']}"
"2019-12-29 14:28:57 [scrapy.extensions.telnet] INFO: Telnet Password: 0704990cc90887cb"
"2019-12-29 14:28:57 [scrapy.middleware] INFO: Enabled extensions:"
"['scrapy.extensions.corestats.CoreStats',"
"'scrapy.extensions.telnet.TelnetConsole',"
"'scrapy.extensions.memusage.MemoryUsage',"
"'scrapy.extensions.logstats.LogStats']"
"2019-12-29 14:28:57 [scrapy.middleware] INFO: Enabled downloader middlewares:"
"['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',"
"'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',"
"'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',"
"'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',"
"'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',"
"'scrapy.downloadermiddlewares.retry.RetryMiddleware',"
"'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',"
"'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',"
"'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',"
"'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',"
"'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',"
"'scrapy.downloadermiddlewares.stats.DownloaderStats']"
"2019-12-29 14:28:57 [scrapy.middleware] INFO: Enabled spider middlewares:"
"['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',"
"'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',"
"'scrapy.spidermiddlewares.referer.RefererMiddleware',"
"'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',"
"'scrapy.spidermiddlewares.depth.DepthMiddleware']"
"2019-12-29 14:28:57 [scrapy.middleware] INFO: Enabled item pipelines:"
"[]"
"2019-12-29 14:28:57 [scrapy.core.engine] INFO: Spider opened"
"2019-12-29 14:28:57 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)"
"2019-12-29 14:28:57 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023"
"2019-12-29 14:28:58 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://quotes.toscrape.com/robots.txt> (referer: None)"
"2019-12-29 14:28:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.toscrape.com/page/1/> (referer: None)"
"2019-12-29 14:28:58 [quotes] DEBUG: Saved file quotes-1.html"
"2019-12-29 14:28:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.toscrape.com/page/2/> (referer: None)"
"2019-12-29 14:28:58 [quotes] DEBUG: Saved file quotes-2.html"
"2019-12-29 14:28:58 [scrapy.core.engine] INFO: Closing spider (finished)"
"2019-12-29 14:28:58 [scrapy.statscollectors] INFO: Dumping Scrapy stats:"
"{'downloader/request_bytes': 678,"
"'downloader/request_count': 3,"
"'downloader/request_method_count/GET': 3,"
"'downloader/response_bytes': 5976,"
"'downloader/response_count': 3,"
"'downloader/response_status_count/200': 2,"
"'downloader/response_status_count/404': 1,"
"'elapsed_time_seconds': 1.302012,"
"'finish_reason': 'finished',"
"'finish_time': datetime.datetime(2019, 12, 29, 8, 58, 58, 594129),"
"'log_count/DEBUG': 5,"
"'log_count/INFO': 10,"
"'memusage/max': 49717248,"
"'memusage/startup': 49713152,"
"'response_received_count': 3,"
"'robotstxt/request_count': 1,"
"'robotstxt/response_count': 1,"
"'robotstxt/response_status_count/404': 1,"
"'scheduler/dequeued': 2,"
"'scheduler/dequeued/memory': 2,"
"'scheduler/enqueued': 2,"
"'scheduler/enqueued/memory': 2,"
"'start_time': datetime.datetime(2019, 12, 29, 8, 58, 57, 292117)}"
"2019-12-29 14:28:58 [scrapy.core.engine] INFO: Spider closed (finished)"
""
"Extracting the data with scrapy"
"scrapy shell 'http://quotes.toscrape.com/page/1/'"
""
"2019-12-29 14:31:43 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: tutorial)"
"2019-12-29 14:31:43 [scrapy.utils.log] INFO: Versions: lxml 4.4.2.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.3 (v3.7.3:ef4ec6ed12, Mar 25 2019, 16:52:21) - [Clang 6.0 (clang-600.0.57)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Darwin-18.7.0-x86_64-i386-64bit"
"2019-12-29 14:31:43 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'tutorial', 'DUPEFILTER_CLASS': 'scrapy.dupefilters.BaseDupeFilter', 'LOGSTATS_INTERVAL': 0, 'NEWSPIDER_MODULE': 'tutorial.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['tutorial.spiders']}"
"2019-12-29 14:31:43 [scrapy.extensions.telnet] INFO: Telnet Password: 56b6407f00569f6f"
"2019-12-29 14:31:43 [scrapy.middleware] INFO: Enabled extensions:"
"['scrapy.extensions.corestats.CoreStats',"
"'scrapy.extensions.telnet.TelnetConsole',"
"'scrapy.extensions.memusage.MemoryUsage']"
"2019-12-29 14:31:44 [scrapy.middleware] INFO: Enabled downloader middlewares:"
"['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',"
"'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',"
"'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',"
"'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',"
"'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',"
"'scrapy.downloadermiddlewares.retry.RetryMiddleware',"
"'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',"
"'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',"
"'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',"
"'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',"
"'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',"
"'scrapy.downloadermiddlewares.stats.DownloaderStats']"
"2019-12-29 14:31:44 [scrapy.middleware] INFO: Enabled spider middlewares:"
"['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',"
"'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',"
"'scrapy.spidermiddlewares.referer.RefererMiddleware',"
"'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',"
"'scrapy.spidermiddlewares.depth.DepthMiddleware']"
"2019-12-29 14:31:44 [scrapy.middleware] INFO: Enabled item pipelines:"
"[]"
"2019-12-29 14:31:44 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023"
"2019-12-29 14:31:44 [scrapy.core.engine] INFO: Spider opened"
"2019-12-29 14:31:44 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://quotes.toscrape.com/robots.txt> (referer: None)"
"2019-12-29 14:31:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.toscrape.com/page/1/> (referer: None)"
"[s] Available Scrapy objects:"
"[s]   scrapy     scrapy module (contains scrapy.Request, scrapy.Selector, etc)"
"[s]   crawler    <scrapy.crawler.Crawler object at 0x1047939b0>"
"[s]   item       {}"
"[s]   request    <GET http://quotes.toscrape.com/page/1/>"
"[s]   response   <200 http://quotes.toscrape.com/page/1/>"
"[s]   settings   <scrapy.settings.Settings object at 0x104793630>"
"[s]   spider     <DefaultSpider 'default' at 0x104c26438>"
"[s] Useful shortcuts:"
"[s]   fetch(url[, redirect=True]) Fetch URL and update local objects (by default, redirects are followed)"
"[s]   fetch(req)                  Fetch a scrapy.Request and update local objects"
"[s]   shelp()           Shell help (print this help)"
"[s]   view(response)    View response in a browser"
">>> response.css('title')"
"[<Selector xpath='descendant-or-self::title' data='<title>Quotes to Scrape</title>'>]"
">>> response.css('title::text').getall()"
"['Quotes to Scrape']"
">>> response.css('title').getall()"
"['<title>Quotes to Scrape</title>']"
">>> response.css('title::text').get()"
"'Quotes to Scrape'"
">>> response.xpath('//title')"
"[<Selector xpath='//title' data='<title>Quotes to Scrape</title>'>]"
">>> response.xpath('//title/text()').get()"
"'Quotes to Scrape'"
""
